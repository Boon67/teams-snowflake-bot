# 📡 Bot Framework Emulator Streaming

## Real-time Delta Streaming to Bot Framework Emulator

This feature enables real-time streaming of AI responses to the Bot Framework Emulator, so users can see the text appearing progressively as it's generated by Snowflake Cortex Agents.

## 🌊 How It Works

### **Server-side Flow:**
1. **Real-time SSE Processing**: Snowflake deltas are processed immediately as they arrive
2. **Delta Callback**: Each text delta triggers a callback to the bot
3. **Progressive Messaging**: Text is accumulated and sent in chunks to the emulator
4. **Final Formatting**: Complete response is formatted and sent at the end

### **User Experience:**
```
User: "who sold the most policies?"

Bot: 🔍 Working on it...

Bot: 🔄 Processing your request...     ▊
     [Text appears progressively in the same message bubble]
     Based on the analysis of your insurance policies data, I can
     determine that Sarah Johnson sold the most policies with a total
     of 247 policies sold this year.

Bot: ✅ Processing complete!
     [Same message bubble now shows complete text]

Bot: [Final formatted response with tables and analysis]
```

## 🎯 Key Features

### **1. Progressive Message Updates**
- **Same message bubble**: Text appears progressively in one message (no multiple bubbles)
- **Character-based updates**: Updates every 30+ characters or 300ms intervals
- **Typewriter effect**: Creates smooth "typing" animation with cursor indicator (▊)
- **Smart throttling**: Prevents overwhelming the Bot Framework with too many updates

### **2. Real-time Indicators**
```javascript
// Stream progress indicators
🔄 Processing your request...    // Initial message
📝 [text chunks]                // Progressive content
✅ Processing complete!          // Stream finished
[Final formatted response]       // Complete result
```

### **3. Fallback Support**
- **Graceful degradation**: Falls back to regular responses if streaming fails
- **Error handling**: Continues working even if individual stream updates fail
- **Compatibility**: Works with both streaming and non-streaming endpoints

## 🔧 Technical Implementation

### **Progressive Update System**
```javascript
const deltaCallback = async (delta) => {
    // Extract text content from each delta
    if (content.type === 'text' && content.text) {
        accumulatedText += content.text;
        
        // Update the same message progressively
        if (shouldUpdate) {
            if (!streamingStarted) {
                // Send initial message
                streamingActivity = await context.sendActivity(
                    MessageFactory.text(`🔄 **Processing...**\n\n${accumulatedText} ▊`)
                );
                streamingStarted = true;
            } else {
                // Update existing message with new content
                await context.updateActivity({
                    type: 'message',
                    id: streamingActivity.id,
                    text: `🔄 **Processing...**\n\n${accumulatedText} ▊`
                });
            }
        }
    }
};
```

### **Progressive Update Configuration**
```javascript
// Progressive update parameters
const THROTTLE_MS = 300;        // Max update frequency (300ms)
const MIN_CHARS = 30;           // Minimum characters before update
const CURSOR_SYMBOL = ' ▊';     // Typing cursor indicator
```

### **Message Flow**
1. **Acknowledgment**: `🔍 Working on it...` (separate message)
2. **Progressive Message**: `🔄 Processing your request... ▊` (starts empty, grows progressively)
3. **Content Updates**: Same message updates with new text as it arrives
4. **Stream Complete**: `✅ Processing complete!` (replaces processing indicator)
5. **Final Response**: Properly formatted response with tables, SQL, etc. (separate message)

## 📊 Debug Output

When `DEBUG_DELTAS=true` is enabled, you'll see detailed streaming logs:

```
📡 Stream delta #1: "Based"
📡 Stream delta #2: " on"
📡 Stream delta #3: " the"
🚀 Started streaming to emulator
📤 Sent streaming chunk: "Based on the analysis..."
📡 Stream delta #15: " policies"
📤 Sent streaming chunk: "I can determine that Sarah..."
✅ Processing complete!
✅ Sent final formatted response
```

## 🎮 User Experience Examples

### **Simple Query**
```
User: "show me total policies"
Bot: 🔍 Working on it...
Bot: 🔄 Processing your request...
     Looking at your insurance
Bot: 📝 policies data, I can see
Bot: 📝 there are 1,247 total policies
Bot: ✅ Processing complete!
Bot: [Formatted table with policy breakdown]
```

### **Complex Analysis**
```
User: "analyze policy trends by agent"
Bot: 🔍 Analyzing your request...
Bot: 🔄 Processing your request...
     I'll analyze the policy trends
Bot: 📝 across different agents to identify
Bot: 📝 patterns in sales performance
Bot: 📝 and growth opportunities
Bot: ✅ Processing complete!
Bot: [Detailed analysis with SQL, tables, and insights]
```

## 🔍 Benefits

### **1. Immediate Feedback**
- Users see the AI is actively processing their request
- No more waiting in silence for complex queries
- Real-time progress indication

### **2. Better User Experience**
- **Engaging**: Users can follow the AI's thought process
- **Responsive**: Immediate visual feedback on query processing
- **Professional**: Smooth, modern streaming experience

### **3. Debug Visibility**
- **Real-time monitoring**: See exactly when deltas arrive
- **Performance tracking**: Monitor streaming speed and timing
- **Issue detection**: Quickly identify bottlenecks or failures

## ⚙️ Configuration

### **Enable Streaming**
```bash
# Start bot with streaming enabled
DEBUG_DELTAS=true npm run dev
```

### **Streaming Settings**
```javascript
// In bot.js - adjust these values for different streaming behavior
const THROTTLE_MS = 500;        // Faster = more frequent updates
const MIN_WORDS = 3;            // Lower = more frequent updates
```

### **Debug Levels**
```bash
DEBUG_DELTAS=true              # Full delta debugging + streaming
SHOW_DELTA_MESSAGES=true       # Basic delta info + streaming
# (no debug flags)             # Just streaming, no debug output
```

## 🚨 Important Notes

### **Bot Framework Emulator Specific**
- **Works best with Bot Framework Emulator**: Real-time updates optimized for emulator
- **Teams compatibility**: May behave differently in production Teams environment
- **Fallback included**: Automatically falls back to regular messages if streaming fails

### **Performance Considerations**
- **Throttled updates**: Prevents overwhelming the Bot Framework with too many messages
- **Word-based chunking**: Sends meaningful text chunks, not character-by-character
- **Graceful degradation**: Continues working even if individual updates fail

### **Message Limits**
- **Bot Framework limits**: Respects message size and frequency limits
- **Chunking support**: Large responses are automatically chunked
- **Error handling**: Robust error handling for streaming failures

## 🧪 Testing

### **Test Progressive Updates**
```bash
# Test progressive message updates (mock simulation)
npm run test-progressive-updates

# Test with real Bot Framework Emulator
DEBUG_DELTAS=true npm run dev
# Then send queries in Bot Framework Emulator
```

### **Test Commands**
```
# Simple queries (short streaming)
"show me total policies"
"who sold the most policies?"

# Complex queries (long streaming, more visible progressive updates)
"analyze policy trends by product type"
"generate a detailed report on agent performance"
```

### **Expected Behavior**
1. **Immediate acknowledgment**: `🔍 Working on it...` (separate message)
2. **Progressive typing**: `🔄 Processing your request... ▊` (same message grows progressively)
3. **Text accumulation**: Text appears character by character with typing cursor
4. **Stream completion**: `✅ Processing complete!` (cursor removed, message finalized)
5. **Final response**: Properly formatted complete answer (separate message)

---

🎉 **Real-time streaming is now active!** Users in Bot Framework Emulator will see AI responses appearing progressively as they're generated, creating a much more engaging and responsive experience!